{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining II Practical Assignment\n",
    "\n",
    "## Iván Marcelo Carrera Izurieta\n",
    "### Programa de Doutoramento em Ciência de Computadores FCUP.\n",
    "\n",
    "#### Predicting Cellular line - Drug Interactions as Recommender System\n",
    "This work presents an analysis for the relationships among cellular lines and pharmaceutical drugs.\n",
    "\n",
    "There are two main source databases for cellular lines: [Cellosaurus](https://web.expasy.org/cellosaurus/)\n",
    "and [ChEMBL](https://www.ebi.ac.uk/chembl/).\n",
    "\n",
    "##### Text processing\n",
    "\n",
    "PubMed publications about each cellular line have been retrieved. Corpus is formed from abstracts, and mapped to cell line identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell line table has columns: Index(['cell_chembl_id', 'cell_description', 'cell_id', 'cell_name',\n",
      "       'cell_source_organism', 'cell_source_tax_id', 'cell_source_tissue',\n",
      "       'cellosaurus_id', 'cl_lincs_id', 'clo_id', 'efo_id'],\n",
      "      dtype='object') \n",
      " and contains information of 1554 cell lines\n",
      "Corpus contains information from 807 cell lines.\n",
      "================================================================================\n",
      "  cell_chembl_id cell_id cell_name cell_source_organism   cell_source_tissue\n",
      "0  CHEMBL3307241       1      DC3F   Cricetulus griseus                 Lung\n",
      "1  CHEMBL3307242       2    P3HR-1         Homo sapiens              Lyphoma\n",
      "2  CHEMBL3307243       3  UCLA P-3         Homo sapiens  Lung Adenocarcinoma\n",
      "3  CHEMBL3307244       4  UMSCC22B         Homo sapiens            Carcinoma\n",
      "4  CHEMBL3307245       5     UMUC3         Homo sapiens    Bladder Carcinoma\n",
      "================================================================================ \n",
      "Corpus:\n",
      "   cell_id                                          documents\n",
      "0        1   Electroporation enhances mitomycin C cytotoxi...\n",
      "1        5   Dihydroartemisinin suppresses bladder cancer ...\n",
      "2       13   Quantification of elastase-like activity in 1...\n",
      "3       21   Correction to: A1CF-Axin2 signal axis regulat...\n",
      "4       27   Cytotoxic effects of fascaplysin against smal...\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cell = pd.read_csv('https://raw.githubusercontent.com/elprofe-ivan/passignment/master/cell_mapping.csv',\n",
    "                   sep=',', error_bad_lines=False, encoding=\"latin-1\")\n",
    "cell['cell_id'] = cell['cell_id'].values.astype(str)\n",
    "print('Cell line table has columns:', cell.columns, '\\n and contains information of', cell.shape[0], 'cell lines')\n",
    "\n",
    "corpus_df = pd.read_csv('https://raw.githubusercontent.com/elprofe-ivan/passignment/master/corpus_df.csv', sep=',', error_bad_lines=False, encoding=\"latin-1\")\n",
    "print('Corpus contains information from', corpus_df.shape[0], 'cell lines.')\n",
    "print('='*80)\n",
    "print(cell[['cell_chembl_id', 'cell_id', 'cell_name',\n",
    "       'cell_source_organism', 'cell_source_tissue']].head())\n",
    "print('='*80, '\\nCorpus:')\n",
    "print(corpus_df.head())\n",
    "print('='*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corpus will characterize cellular lines, and will help measure distances between cellular lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================ \n",
      "Stemmed Corpus:\n",
      "   cell_id                                            stemmed\n",
      "0        1  electropor enhanc mitomycin C cytotox on t24 b...\n",
      "1        5  dihydroartemisinin suppress bladder cancer cel...\n",
      "2       13  quantif of elastase-lik activ in 13 human canc...\n",
      "3       21  correct to a1cf-axin2 signal axi regul apoptos...\n",
      "4       27  cytotox effect of fascaplysin against small ce...\n",
      "================================================================================\n",
      "26080 different words in corpus\n",
      "================================================================================\n",
      "Top 20 frequent words:\n",
      "[('cell', 1.0012383902511466), ('line', 1.002478316014467), ('wa', 1.0429901849313683), ('use', 1.0798364583173345), ('studi', 1.0879118723228798), ('result', 1.0960530299065798), ('express', 1.1001485987713169), ('thi', 1.1015175243786586), ('effect', 1.1139229212361463), ('human', 1.1180924894728712), ('activ', 1.137783702363053), ('cancer', 1.1392051667104304), ('tumor', 1.1932723879807061), ('increas', 1.2008082186694091), ('protein', 1.2008082186694091), ('treatment', 1.2008082186694091), ('inhibit', 1.206878040036485), ('induc', 1.2099268228858433), ('investig', 1.225311741725323), ('compar', 1.2330938821673778)]\n",
      "================================================================================\n",
      "Cell Similarity matrix: (807, 807)\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "stem = PorterStemmer()\n",
    "stemmed_corpus = list()\n",
    "for doc in corpus_df['documents']:\n",
    "    doc = doc.replace('.','').replace(',','').replace(';','').replace(':','')\n",
    "    stemmed_corpus.append(' '.join([stem.stem(x) for x in doc.split()]))\n",
    "\n",
    "corpus_df['stemmed'] = stemmed_corpus\n",
    "print('='*80, '\\nStemmed Corpus:')\n",
    "print(corpus_df[['cell_id', 'stemmed']].head())\n",
    "print('='*80)\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=1.0, min_df=2, strip_accents='ascii', stop_words='english',\n",
    "                             token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b')\n",
    "dtm = vectorizer.fit_transform(corpus_df['stemmed'])\n",
    "print(dtm.shape[1], 'different words in corpus')\n",
    "print('='*80)\n",
    "\n",
    "wordfreq = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n",
    "print('Top 20 frequent words:')\n",
    "print(sorted(wordfreq.items(), key=lambda x: x[1])[:20])\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "dtm_df = pd.DataFrame(dtm.todense())\n",
    "sim_mtx = pd.DataFrame(cosine_similarity(dtm_df), index=corpus_df.index, columns=corpus_df.index)\n",
    "print('='*80)\n",
    "print('Cell Similarity matrix:', sim_mtx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell line similarity will be helpful when looking for new interactions.\n",
    "\n",
    "##### Collaborative-Filtering Recommender System\n",
    "\n",
    "Cell line - Compound interactions are recorded in ChEMBL database.\n",
    "However, not every cell line - compound combination is annotated in the database.\n",
    "Using matrix decomposition, values can be computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compound table has columns: Index(['id', 'smile', 'fp'], dtype='object')\n",
      "   id                                              smile  \\\n",
      "0   0  COc1cccc2C(=O)c3c(O)c4C[C@](O)(C[C@H](O[C@H]5C...   \n",
      "1   1  CN1C2N(CCc3c2n(CCCCCCOc4no[n+]([O-])c4S(=O)(=O...   \n",
      "2   2  CCOc1ccc(Cl)cc1c2cc(Nc3cccc(c3)[N+](=O)[O-])nc...   \n",
      "3   3   O=C1N[C@@H](Cc2c[nH]c3ccccc23)C(=O)N4CCC[C@@H]14   \n",
      "4   4          CCc1ccccc1NS(=O)(=O)c2ccc(NC(=O)NCCCl)cc2   \n",
      "\n",
      "                                                  fp  \n",
      "0  1101000000000011000001010000001011101000011100...  \n",
      "1  0000100000000110000000000001101001000000000001...  \n",
      "2  0000000000000001000000000000000001000000000001...  \n",
      "3  0000110000100000000100000000101000000000000000...  \n",
      "4  0000100000000000000101000000000001000000000000...  \n",
      "\n",
      "fp represents Morgan Fingerprint, an expression used in Cheminformatics to represent chemical compounds as a bit string\n",
      "================================================================================\n",
      "Cell lines report activities with between 21853 and 10 compounds\n",
      "Compounds report activities with between 664 and 10 cell lines\n",
      "Number of cells:  875\n",
      "Number of compounds:  1207\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Compounds and cell lines are described in CSV\n",
    "compound = pd.read_csv('https://raw.githubusercontent.com/elprofe-ivan/passignment/master/comp_recsys.csv', sep=',', error_bad_lines=False, encoding=\"latin-1\")\n",
    "print('Compound table has columns:', compound.columns)\n",
    "print(compound.head())\n",
    "print('\\nfp represents Morgan Fingerprint, an expression used in Cheminformatics to represent chemical compounds as a bit string')\n",
    "print('='*80)\n",
    "# Table activity contains the relations between compounds and cells\n",
    "# When a chemical compound has a reported activity on a cell line, 'active' column is set to 1,\n",
    "# and when a chemical compound has a reported inactivity on a cell line, 'active' is set to 0\n",
    "activity = pd.read_csv('https://raw.githubusercontent.com/elprofe-ivan/passignment/master/activity_recsys.csv', sep=',', error_bad_lines=False, encoding=\"latin-1\")\n",
    "activity['cell_id'] = activity['cell_id'].values.astype(str)\n",
    "# print(activity.head())\n",
    "\n",
    "cell_activity = pd.merge(activity, cell, on='cell_id')\n",
    "cols = ['cell_description', 'cell_source_organism', 'cell_source_tax_id', 'cell_source_tissue', 'cl_lincs_id', 'clo_id', 'efo_id']\n",
    "cell_activity.drop(cols, axis=1, inplace=True)\n",
    "\n",
    "activity_count = (cell_activity.\n",
    "     groupby(by = ['cell_name'])['comp_id'].\n",
    "     count().\n",
    "     reset_index().\n",
    "     rename(columns = {'comp_id': 'comp_count'})\n",
    "     [['cell_name', 'comp_count']]\n",
    "    )\n",
    "\n",
    "# Filter cells that report less than 10 activities\n",
    "threshold = 10\n",
    "activity_count = activity_count.query('comp_count >= @threshold')\n",
    "print('Cell lines report activities with between', activity_count['comp_count'].max(), 'and', \n",
    "      activity_count['comp_count'].min(), 'compounds')\n",
    "\n",
    "compound_activity = pd.merge(activity_count, cell_activity, left_on='cell_name', right_on='cell_name', how='left')\n",
    "compound_count = (compound_activity.\n",
    "     groupby(by = ['comp_id'])['active'].\n",
    "     count().\n",
    "     reset_index().\n",
    "     rename(columns = {'active': 'activitycount_comp'})\n",
    "     [['comp_id', 'activitycount_comp']]\n",
    "    )\n",
    "\n",
    "# Filter compounds that report less than 10 activities\n",
    "threshold = 10\n",
    "compound_count = compound_count.query('activitycount_comp >= @threshold')\n",
    "print('Compounds report activities with between', compound_count['activitycount_comp'].max(), 'and',\n",
    "      compound_count['activitycount_comp'].min(), 'cell lines')\n",
    "\n",
    "combined = compound_activity.merge(compound_count, left_on = 'comp_id', right_on = 'comp_id', how = 'inner')\n",
    "\n",
    "print('Number of cells: ', combined['cell_name'].nunique())\n",
    "print('Number of compounds: ', combined['comp_id'].nunique())\n",
    "\n",
    "combined['active'] = combined['active'].values.astype(float)\n",
    "combined['cell_id'] = combined['cell_id'].values.astype(str)\n",
    "combined['comp_id'] = combined['comp_id'].values.astype(str)\n",
    "\n",
    "combined = combined.drop_duplicates(['comp_id', 'cell_id'])\n",
    "compound_cell_matrix = combined.pivot(index='comp_id', columns='cell_id', values='active')\n",
    "# inactivities are considered as -1\n",
    "compound_cell_matrix = compound_cell_matrix.replace(to_replace=0.0, value=-1.0)\n",
    "compound_cell_matrix.fillna(0, inplace=True)\n",
    "\n",
    "compounds = compound_cell_matrix.index.tolist()\n",
    "cells = compound_cell_matrix.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For computing matrix decomposition, TensorFlow package is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations computed\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "num_input = combined['cell_id'].nunique()\n",
    "num_hidden_1 = 10\n",
    "num_hidden_2 = 5\n",
    "\n",
    "X = tf.placeholder(tf.float64, [None, num_input])\n",
    "\n",
    "weights = {\n",
    "    'encoder_h1': tf.Variable(tf.random_normal([num_input, num_hidden_1], dtype=tf.float64)),\n",
    "    'encoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_hidden_2], dtype=tf.float64)),\n",
    "    'decoder_h1': tf.Variable(tf.random_normal([num_hidden_2, num_hidden_1], dtype=tf.float64)),\n",
    "    'decoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_input], dtype=tf.float64)),\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'encoder_b1': tf.Variable(tf.random_normal([num_hidden_1], dtype=tf.float64)),\n",
    "    'encoder_b2': tf.Variable(tf.random_normal([num_hidden_2], dtype=tf.float64)),\n",
    "    'decoder_b1': tf.Variable(tf.random_normal([num_hidden_1], dtype=tf.float64)),\n",
    "    'decoder_b2': tf.Variable(tf.random_normal([num_input], dtype=tf.float64)),\n",
    "}\n",
    "\n",
    "def encoder(x):\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']), biases['encoder_b1']))\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']), biases['encoder_b2']))\n",
    "    return layer_2\n",
    "\n",
    "def decoder(x):\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']), biases['decoder_b1']))\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']), biases['decoder_b2']))\n",
    "    return layer_2\n",
    "\n",
    "encoder_op = encoder(X)\n",
    "decoder_op = decoder(encoder_op)\n",
    "y_pred = decoder_op\n",
    "y_true = X\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y_true, y_pred)\n",
    "optimizer = tf.train.RMSPropOptimizer(0.03).minimize(loss)\n",
    "eval_x = tf.placeholder(tf.int32, )\n",
    "eval_y = tf.placeholder(tf.int32, )\n",
    "pre, pre_op = tf.metrics.precision(labels=eval_x, predictions=eval_y)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "local_init = tf.local_variables_initializer()\n",
    "pred_data = pd.DataFrame()\n",
    "\n",
    "# top_recomm represent how many top recommendations do you want to store\n",
    "top_recomm = 10\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "with tf.Session() as session:\n",
    "    epochs = 100\n",
    "    batch_size = 35\n",
    "\n",
    "    session.run(init)\n",
    "    session.run(local_init)\n",
    "\n",
    "    num_batches = int(compound_cell_matrix.shape[0] / batch_size)\n",
    "    compound_cell_matrix = np.array_split(compound_cell_matrix, num_batches)\n",
    "\n",
    "    for i in range(epochs):\n",
    "\n",
    "        avg_cost = 0\n",
    "        for batch in compound_cell_matrix:\n",
    "            _, l = session.run([optimizer, loss], feed_dict={X: batch})\n",
    "            avg_cost += l\n",
    "\n",
    "        avg_cost /= num_batches\n",
    "\n",
    "#         print(\"epoch: {} Loss: {}\".format(i + 1, avg_cost))\n",
    "\n",
    "    compound_cell_matrix = np.concatenate(compound_cell_matrix, axis=0)\n",
    "\n",
    "    preds = session.run(decoder_op, feed_dict={X: compound_cell_matrix})\n",
    "\n",
    "    pred_data = pred_data.append(pd.DataFrame(preds))\n",
    "\n",
    "    pred_data = pred_data.stack().reset_index(name='active')\n",
    "    pred_data.columns = ['comp_id', 'cell_id', 'active']\n",
    "    pred_data['comp_id'] = pred_data['comp_id'].map(lambda value: compounds[value])\n",
    "    pred_data['cell_id'] = pred_data['cell_id'].map(lambda value: cells[value])\n",
    "\n",
    "    keys = ['comp_id', 'cell_id']\n",
    "    index_1 = pred_data.set_index(keys).index\n",
    "    index_2 = combined.set_index(keys).index\n",
    "\n",
    "    recomm = pred_data[~index_1.isin(index_2)]\n",
    "    recomm = recomm.sort_values(['comp_id', 'active'], ascending=[True, False])\n",
    "    # Comment next line for retrieving all recommendations\n",
    "    recomm = recomm.groupby('comp_id').head(top_recomm)\n",
    "   \n",
    "\n",
    "recomm['comp_id'] = recomm['comp_id'].values.astype(int) # for compatibility\n",
    "print('Recommendations computed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sample of recommendations can be shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272393     13010\n",
      "198685    122469\n",
      "Name: comp_id, dtype: int64\n",
      "================================================================================\n",
      "        comp_id cell_id    active\n",
      "272352    13010     721  0.469569\n",
      "272239    13010     555  0.416721\n",
      "272310    13010     655  0.389963\n",
      "272109    13010     325  0.346262\n",
      "272294    13010     635  0.252373\n",
      "272333    13010     691  0.230858\n",
      "272188    13010     478  0.202418\n",
      "272393    13010     791  0.187265\n",
      "272220    13010     525  0.142051\n",
      "272374    13010     757  0.138680\n",
      "        comp_id cell_id    active\n",
      "198768   122469     721  0.523102\n",
      "198728   122469     657  0.486062\n",
      "198788   122469     755  0.466567\n",
      "198658   122469     560  0.344890\n",
      "198672   122469     577  0.335617\n",
      "198525   122469     325  0.319936\n",
      "198777   122469     743  0.301083\n",
      "198685   122469     600  0.296588\n",
      "198786   122469     753  0.281515\n",
      "198751   122469     693  0.272080\n"
     ]
    }
   ],
   "source": [
    "sample = recomm['comp_id'].sample(2)\n",
    "print(sample)\n",
    "print('='*80)\n",
    "for comp_id in sample:\n",
    "    print(recomm[recomm['comp_id']==comp_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combining Recommendations\n",
    "\n",
    "For a cold-start recommendation, let's imagine a novel compound which has no reported activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 not in Collaborative-Filtering Recommendations\n",
      "Reported cellular lines for 1  : ['646']\n",
      "Similar cells to 646 : []\n",
      "Compound id 1 has 2 similar compounds: [1022, 550]\n",
      "1022 not in Collaborative-Filtering Recommendations\n",
      "Reported cellular lines for 1022  : ['646' '687' '721']\n",
      "Similar cells to 646 : []\n",
      "Similar cells to 687 : []\n",
      "Similar cells to 721 : [773]\n",
      "550 not in Collaborative-Filtering Recommendations\n",
      "Reported cellular lines for 550  : ['436' '726' '791']\n",
      "Similar cells to 436 : []\n",
      "Similar cells to 726 : [20, 671]\n",
      "Similar cells to 791 : [521]\n",
      "Candidate cells for 1 : {'721', 773, 521, '687', '646', '436', 20, '726', '791', 671}\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "\n",
    "def fp_distance(elem_):\n",
    "    i, j = elem_[0], elem_[1]\n",
    "    fp_i = np.array(list(compound.iloc[i]['fp']), dtype=int)\n",
    "    fp_j = np.array(list(compound.iloc[j]['fp']), dtype=int)\n",
    "    s = jaccard_score(y_true=fp_i, y_pred=fp_j)\n",
    "    return s\n",
    "\n",
    "\n",
    "def distance_list(i, cutoff=0.3):\n",
    "    # print('Computing distance with', n_comp,'compounds.')\n",
    "    n_comp = combined['comp_id'].nunique()\n",
    "    iter_ = zip([i]*n_comp, range(n_comp))\n",
    "    # This should be done in parallel\n",
    "    # Binder does not support multiprocessing package\n",
    "    dist_list = list()\n",
    "    for item_ in iter_:\n",
    "        dist_list.append(fp_distance(item_))\n",
    "    dist_list = zip(compound['id'], dist_list)\n",
    "    # Return only compounds that have a similarity higher than cutoff\n",
    "    dist_list = list(filter(lambda elem_: elem_[1] > cutoff, dist_list))\n",
    "    return sorted(dist_list, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "def cell_distance_list(cell_id, cutoff=0.3):\n",
    "    cell_list = sim_mtx[cell_id][sim_mtx[cell_id] > cutoff]\n",
    "    return cell_list.drop(cell_id)\n",
    "\n",
    "\n",
    "def get_cells_for_comp(comp_id):\n",
    "    return activity[activity['comp_id'] == int(comp_id)]\n",
    "\n",
    "\n",
    "def get_comps_for_cell(cell_id):\n",
    "    return activity[activity['cell_id'] == cell_id]\n",
    "\n",
    "\n",
    "def cold_start_recomm(example_comp_id):\n",
    "    s = recomm.loc[recomm['comp_id'] == example_comp_id]\n",
    "    candidate_cells = set()\n",
    "    if s.empty:\n",
    "        print(example_comp_id, 'not in Collaborative-Filtering Recommendations')\n",
    "        reported_cells = get_cells_for_comp(example_comp_id)['cell_id'].values\n",
    "        candidate_cells.update(reported_cells)\n",
    "        print('Reported cellular lines for', example_comp_id,' :', reported_cells)\n",
    "        for cell in reported_cells:\n",
    "            similar_cells = list(cell_distance_list(int(cell)).index)\n",
    "            candidate_cells.update(similar_cells)\n",
    "            print('Similar cells to', cell,':', similar_cells)\n",
    "            \n",
    "        dist_list = distance_list(example_comp_id)\n",
    "        if len(dist_list) > 1:\n",
    "            print('Compound id', example_comp_id, 'has', len(dist_list)-1, 'similar compounds:',\n",
    "                  [dist_item[0] for dist_item in dist_list[1:]])\n",
    "            for comp in dist_list[1:]:\n",
    "                s = recomm.loc[recomm['comp_id'] == comp[0]]\n",
    "                if s.empty:\n",
    "                    print(comp[0], 'not in Collaborative-Filtering Recommendations')\n",
    "                    reported_cells = get_cells_for_comp(comp[0])['cell_id'].values\n",
    "                    candidate_cells.update(reported_cells)\n",
    "                    print('Reported cellular lines for', comp[0],' :', reported_cells)\n",
    "                    for cell in reported_cells:\n",
    "                        similar_cells = list(cell_distance_list(int(cell)).index)\n",
    "                        candidate_cells.update(similar_cells)\n",
    "                        print('Similar cells to', cell,':', similar_cells)\n",
    "                else:\n",
    "                    print('Collaborative-Filtering Recommendations for: ', comp[0])\n",
    "                    print(s['cell_id'].values)\n",
    "        else:\n",
    "            print('Compound id', example_comp_id, 'has no similar compounds')\n",
    "        return candidate_cells\n",
    "    else:\n",
    "        print('Collaborative-Filtering Recommendations for: ', example_comp_id)\n",
    "        print(s['cell_id'].values)\n",
    "        return s['cell_id'].values\n",
    "    \n",
    "            \n",
    "            \n",
    "\n",
    "example_comp_id = 1\n",
    "print('Candidate cells for', example_comp_id, ':',cold_start_recomm(example_comp_id))\n",
    "print('='*80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}