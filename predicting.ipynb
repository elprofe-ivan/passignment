{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Data Mining II Practical Assignment\n\n## Iván Marcelo Carrera Izurieta\n### Programa de Doutoramento em Ciência de Computadores FCUP.\n\n#### Predicting Cellular line - Drug Interactions as Recommender System\nThis work presents an analysis for the relationships among cellular lines and pharmaceutical drugs.\n\nThere are two main source databases for cellular lines: [Cellosaurus](https://web.expasy.org/cellosaurus/)\nand [ChEMBL](https://www.ebi.ac.uk/chembl/).\n\n##### Text processing\n\nPubMed publications about each cellular line have been retrieved. Corpus is formed from abstracts, and mapped to cell line identifiers."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\ncell = pd.read_csv('/kaggle/input/recsys/cell_mapping.csv', sep=',', error_bad_lines=False, encoding=\"latin-1\")\ncell['cell_id'] = cell['cell_id'].values.astype(str)\nprint('Cell line table has columns:', cell.columns, '\\n and contains information of', cell.shape[0], 'cell lines')\n\ncorpus_df = pd.read_csv('/kaggle/input/recsys/corpus_df.csv', sep=',', error_bad_lines=False, encoding=\"latin-1\")\nprint('Corpus contains information from', corpus_df.shape[0], 'cell lines.')\nprint('='*80)\nprint(cell[['cell_chembl_id', 'cell_id', 'cell_name',\n       'cell_source_organism', 'cell_source_tissue']].head())\nprint('='*80, '\\nCorpus:')\nprint(corpus_df.head())\nprint('='*80)","execution_count":1,"outputs":[{"output_type":"stream","text":"Cell line table has columns: Index(['cell_chembl_id', 'cell_description', 'cell_id', 'cell_name',\n       'cell_source_organism', 'cell_source_tax_id', 'cell_source_tissue',\n       'cellosaurus_id', 'cl_lincs_id', 'clo_id', 'efo_id'],\n      dtype='object') \n and contains information of 1554 cell lines\nCorpus contains information from 807 cell lines.\n================================================================================\n  cell_chembl_id cell_id cell_name cell_source_organism   cell_source_tissue\n0  CHEMBL3307241       1      DC3F   Cricetulus griseus                 Lung\n1  CHEMBL3307242       2    P3HR-1         Homo sapiens              Lyphoma\n2  CHEMBL3307243       3  UCLA P-3         Homo sapiens  Lung Adenocarcinoma\n3  CHEMBL3307244       4  UMSCC22B         Homo sapiens            Carcinoma\n4  CHEMBL3307245       5     UMUC3         Homo sapiens    Bladder Carcinoma\n================================================================================ \nCorpus:\n   cell_id                                          documents\n0        1   Electroporation enhances mitomycin C cytotoxi...\n1        5   Dihydroartemisinin suppresses bladder cancer ...\n2       13   Quantification of elastase-like activity in 1...\n3       21   Correction to: A1CF-Axin2 signal axis regulat...\n4       27   Cytotoxic effects of fascaplysin against smal...\n================================================================================\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Corpus will characterize cellular lines, and will help measure distances between cellular lines."},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem.porter import PorterStemmer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nstem = PorterStemmer()\nstemmed_corpus = list()\nfor doc in corpus_df['documents']:\n    doc = doc.replace('.','').replace(',','').replace(';','').replace(':','')\n    stemmed_corpus.append(' '.join([stem.stem(x) for x in doc.split()]))\n\ncorpus_df['stemmed'] = stemmed_corpus\nprint('='*80, '\\nStemmed Corpus:')\nprint(corpus_df[['cell_id', 'stemmed']].head())\nprint('='*80)\nvectorizer = TfidfVectorizer(sublinear_tf=True, max_df=1.0, min_df=2, strip_accents='ascii', stop_words='english',\n                             token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b')\ndtm = vectorizer.fit_transform(corpus_df['stemmed'])\nprint(dtm.shape[1], 'different words in corpus')\nprint('='*80)\n\nwordfreq = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\nprint('Top 20 frequent words:')\nprint(sorted(wordfreq.items(), key=lambda x: x[1])[:20])\n\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ndtm_df = pd.DataFrame(dtm.todense())\nsim_mtx = pd.DataFrame(cosine_similarity(dtm_df), index=corpus_df.index, columns=corpus_df.index)\nprint('='*80)\nprint('Cell Similarity matrix:', sim_mtx.shape)","execution_count":2,"outputs":[{"output_type":"stream","text":"================================================================================ \nStemmed Corpus:\n   cell_id                                            stemmed\n0        1  electropor enhanc mitomycin C cytotox on t24 b...\n1        5  dihydroartemisinin suppress bladder cancer cel...\n2       13  quantif of elastase-lik activ in 13 human canc...\n3       21  correct to a1cf-axin2 signal axi regul apoptos...\n4       27  cytotox effect of fascaplysin against small ce...\n================================================================================\n26080 different words in corpus\n================================================================================\nTop 20 frequent words:\n[('cell', 1.0012383902511466), ('line', 1.002478316014467), ('wa', 1.0429901849313683), ('use', 1.0798364583173345), ('studi', 1.0879118723228798), ('result', 1.0960530299065798), ('express', 1.1001485987713169), ('thi', 1.1015175243786586), ('effect', 1.1139229212361463), ('human', 1.1180924894728712), ('activ', 1.137783702363053), ('cancer', 1.1392051667104304), ('tumor', 1.1932723879807061), ('increas', 1.2008082186694091), ('protein', 1.2008082186694091), ('treatment', 1.2008082186694091), ('inhibit', 1.206878040036485), ('induc', 1.2099268228858433), ('investig', 1.225311741725323), ('compar', 1.2330938821673778)]\n================================================================================\nCell Similarity matrix: (807, 807)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Cell line similarity will be helpful when looking for new interactions.\n\n##### Collaborative-Filtering Recommender System\n\nCell line - Compound interactions are recorded in ChEMBL database.\nHowever, not every cell line - compound combination is annotated in the database.\nUsing matrix decomposition, values can be computed."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\n# Compounds and cell lines are described in CSV\ncompound = pd.read_csv('/kaggle/input/recsys/comp_recsys.csv', sep=',', error_bad_lines=False, encoding=\"latin-1\")\nprint('Compound table has columns:', compound.columns)\nprint(compound.head())\nprint('\\nfp represents Morgan Fingerprint, an expression used in Cheminformatics to represent chemical compounds as a bit string')\nprint('='*80)\n# Table activity contains the relations between compounds and cells\n# When a chemical compound has a reported activity on a cell line, 'active' column is set to 1,\n# and when a chemical compound has a reported inactivity on a cell line, 'active' is set to 0\nactivity = pd.read_csv('/kaggle/input/recsys/activity_recsys.csv', sep=',', error_bad_lines=False, encoding=\"latin-1\")\nactivity['cell_id'] = activity['cell_id'].values.astype(str)\n# print(activity.head())\n\ncell_activity = pd.merge(activity, cell, on='cell_id')\ncols = ['cell_description', 'cell_source_organism', 'cell_source_tax_id', 'cell_source_tissue', 'cl_lincs_id', 'clo_id', 'efo_id']\ncell_activity.drop(cols, axis=1, inplace=True)\n\nactivity_count = (cell_activity.\n     groupby(by = ['cell_name'])['comp_id'].\n     count().\n     reset_index().\n     rename(columns = {'comp_id': 'comp_count'})\n     [['cell_name', 'comp_count']]\n    )\n\n# Filter cells that report less than 10 activities\nthreshold = 10\nactivity_count = activity_count.query('comp_count >= @threshold')\nprint('Cell lines report activities with between', activity_count['comp_count'].max(), 'and', \n      activity_count['comp_count'].min(), 'compounds')\n\ncompound_activity = pd.merge(activity_count, cell_activity, left_on='cell_name', right_on='cell_name', how='left')\ncompound_count = (compound_activity.\n     groupby(by = ['comp_id'])['active'].\n     count().\n     reset_index().\n     rename(columns = {'active': 'activitycount_comp'})\n     [['comp_id', 'activitycount_comp']]\n    )\n\n# Filter compounds that report less than 10 activities\nthreshold = 10\ncompound_count = compound_count.query('activitycount_comp >= @threshold')\nprint('Compounds report activities with between', compound_count['activitycount_comp'].max(), 'and',\n      compound_count['activitycount_comp'].min(), 'cell lines')\n\ncombined = compound_activity.merge(compound_count, left_on = 'comp_id', right_on = 'comp_id', how = 'inner')\n\nprint('Number of cells: ', combined['cell_name'].nunique())\nprint('Number of compounds: ', combined['comp_id'].nunique())\n\ncombined['active'] = combined['active'].values.astype(float)\ncombined['cell_id'] = combined['cell_id'].values.astype(str)\ncombined['comp_id'] = combined['comp_id'].values.astype(str)\n\ncombined = combined.drop_duplicates(['comp_id', 'cell_id'])\ncompound_cell_matrix = combined.pivot(index='comp_id', columns='cell_id', values='active')\n# inactivities are considered as -1\ncompound_cell_matrix = compound_cell_matrix.replace(to_replace=0.0, value=-1.0)\ncompound_cell_matrix.fillna(0, inplace=True)\n\ncompounds = compound_cell_matrix.index.tolist()\ncells = compound_cell_matrix.columns.tolist()","execution_count":3,"outputs":[{"output_type":"stream","text":"Compound table has columns: Index(['id', 'smile', 'fp'], dtype='object')\n   id                                              smile  \\\n0   0  COc1cccc2C(=O)c3c(O)c4C[C@](O)(C[C@H](O[C@H]5C...   \n1   1  CN1C2N(CCc3c2n(CCCCCCOc4no[n+]([O-])c4S(=O)(=O...   \n2   2  CCOc1ccc(Cl)cc1c2cc(Nc3cccc(c3)[N+](=O)[O-])nc...   \n3   3   O=C1N[C@@H](Cc2c[nH]c3ccccc23)C(=O)N4CCC[C@@H]14   \n4   4          CCc1ccccc1NS(=O)(=O)c2ccc(NC(=O)NCCCl)cc2   \n\n                                                  fp  \n0  1101000000000011000001010000001011101000011100...  \n1  0000100000000110000000000001101001000000000001...  \n2  0000000000000001000000000000000001000000000001...  \n3  0000110000100000000100000000101000000000000000...  \n4  0000100000000000000101000000000001000000000000...  \n\nfp represents Morgan Fingerprint, an expression used in Cheminformatics to represent chemical compounds as a bit string\n================================================================================\nCell lines report activities with between 21853 and 10 compounds\nCompounds report activities with between 664 and 10 cell lines\nNumber of cells:  875\nNumber of compounds:  1207\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"For computing matrix decomposition, TensorFlow package is used."},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\n\nnum_input = combined['cell_id'].nunique()\nnum_hidden_1 = 10\nnum_hidden_2 = 5\n\nX = tf.placeholder(tf.float64, [None, num_input])\n\nweights = {\n    'encoder_h1': tf.Variable(tf.random_normal([num_input, num_hidden_1], dtype=tf.float64)),\n    'encoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_hidden_2], dtype=tf.float64)),\n    'decoder_h1': tf.Variable(tf.random_normal([num_hidden_2, num_hidden_1], dtype=tf.float64)),\n    'decoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_input], dtype=tf.float64)),\n}\n\nbiases = {\n    'encoder_b1': tf.Variable(tf.random_normal([num_hidden_1], dtype=tf.float64)),\n    'encoder_b2': tf.Variable(tf.random_normal([num_hidden_2], dtype=tf.float64)),\n    'decoder_b1': tf.Variable(tf.random_normal([num_hidden_1], dtype=tf.float64)),\n    'decoder_b2': tf.Variable(tf.random_normal([num_input], dtype=tf.float64)),\n}\n\ndef encoder(x):\n    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']), biases['encoder_b1']))\n    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']), biases['encoder_b2']))\n    return layer_2\n\ndef decoder(x):\n    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']), biases['decoder_b1']))\n    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']), biases['decoder_b2']))\n    return layer_2\n\nencoder_op = encoder(X)\ndecoder_op = decoder(encoder_op)\ny_pred = decoder_op\ny_true = X\n\nloss = tf.losses.mean_squared_error(y_true, y_pred)\noptimizer = tf.train.RMSPropOptimizer(0.03).minimize(loss)\neval_x = tf.placeholder(tf.int32, )\neval_y = tf.placeholder(tf.int32, )\npre, pre_op = tf.metrics.precision(labels=eval_x, predictions=eval_y)\n\ninit = tf.global_variables_initializer()\nlocal_init = tf.local_variables_initializer()\npred_data = pd.DataFrame()\n\n# top_recomm represent how many top recommendations do you want to store\ntop_recomm = 10\n\nimport numpy as np\n\nwith tf.Session() as session:\n    epochs = 100\n    batch_size = 35\n\n    session.run(init)\n    session.run(local_init)\n\n    num_batches = int(compound_cell_matrix.shape[0] / batch_size)\n    compound_cell_matrix = np.array_split(compound_cell_matrix, num_batches)\n\n    for i in range(epochs):\n\n        avg_cost = 0\n        for batch in compound_cell_matrix:\n            _, l = session.run([optimizer, loss], feed_dict={X: batch})\n            avg_cost += l\n\n        avg_cost /= num_batches\n\n#         print(\"epoch: {} Loss: {}\".format(i + 1, avg_cost))\n\n    compound_cell_matrix = np.concatenate(compound_cell_matrix, axis=0)\n\n    preds = session.run(decoder_op, feed_dict={X: compound_cell_matrix})\n\n    pred_data = pred_data.append(pd.DataFrame(preds))\n\n    pred_data = pred_data.stack().reset_index(name='active')\n    pred_data.columns = ['comp_id', 'cell_id', 'active']\n    pred_data['comp_id'] = pred_data['comp_id'].map(lambda value: compounds[value])\n    pred_data['cell_id'] = pred_data['cell_id'].map(lambda value: cells[value])\n\n    keys = ['comp_id', 'cell_id']\n    index_1 = pred_data.set_index(keys).index\n    index_2 = combined.set_index(keys).index\n\n    recomm = pred_data[~index_1.isin(index_2)]\n    recomm = recomm.sort_values(['comp_id', 'active'], ascending=[True, False])\n    # Comment next line for retrieving all recommendations\n    recomm = recomm.groupby('comp_id').head(top_recomm)\n   \n\nrecomm['comp_id'] = recomm['comp_id'].values.astype(int) # for compatibility\nprint('Recommendations computed')","execution_count":4,"outputs":[{"output_type":"stream","text":"Recommendations computed\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"A sample of recommendations can be shown:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = recomm['comp_id'].sample(2)\nprint(sample)\nprint('='*80)\nfor comp_id in sample:\n    print(recomm[recomm['comp_id']==comp_id])","execution_count":5,"outputs":[{"output_type":"stream","text":"272393     13010\n198685    122469\nName: comp_id, dtype: int64\n================================================================================\n        comp_id cell_id    active\n272352    13010     721  0.469569\n272239    13010     555  0.416721\n272310    13010     655  0.389963\n272109    13010     325  0.346262\n272294    13010     635  0.252373\n272333    13010     691  0.230858\n272188    13010     478  0.202418\n272393    13010     791  0.187265\n272220    13010     525  0.142051\n272374    13010     757  0.138680\n        comp_id cell_id    active\n198768   122469     721  0.523102\n198728   122469     657  0.486062\n198788   122469     755  0.466567\n198658   122469     560  0.344890\n198672   122469     577  0.335617\n198525   122469     325  0.319936\n198777   122469     743  0.301083\n198685   122469     600  0.296588\n198786   122469     753  0.281515\n198751   122469     693  0.272080\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"##### Combining Recommendations\n\nFor a cold-start recommendation, let's imagine a novel compound which has no reported activities."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import jaccard_score\nfrom multiprocessing import Pool\n\n\ndef fp_distance(elem_):\n    i, j = elem_[0], elem_[1]\n    fp_i = np.array(list(compound.iloc[i]['fp']), dtype=int)\n    fp_j = np.array(list(compound.iloc[j]['fp']), dtype=int)\n    s = jaccard_score(y_true=fp_i, y_pred=fp_j)\n    return s\n\n\ndef distance_list(i, cutoff=0.3):\n#     print('Computing distance with', n_comp,'compounds.')\n    n_comp = combined['comp_id'].nunique()\n    iter_ = zip([i]*n_comp, range(n_comp))\n    process_pool = Pool(processes=40)\n    dist_list = process_pool.map(func=fp_distance, iterable=iter_)\n    dist_list = zip(compound['id'], dist_list)\n    # Return only compounds that have a similarity higher than cutoff\n    dist_list = list(filter(lambda elem_: elem_[1] > cutoff, dist_list))\n    return sorted(dist_list, key=lambda x: x[1], reverse=True)\n\n\ndef cell_distance_list(cell_id, cutoff=0.3):\n    cell_list = sim_mtx[cell_id][sim_mtx[cell_id] > cutoff]\n    return cell_list.drop(cell_id)\n\n\ndef get_cells_for_comp(comp_id):\n    return activity[activity['comp_id'] == int(comp_id)]\n\n\ndef get_comps_for_cell(cell_id):\n    return activity[activity['cell_id'] == cell_id]\n\n\ndef cold_start_recomm(example_comp_id):\n    s = recomm.loc[recomm['comp_id'] == example_comp_id]\n    candidate_cells = set()\n    if s.empty:\n        print(example_comp_id, 'not in Collaborative-Filtering Recommendations')\n        reported_cells = get_cells_for_comp(example_comp_id)['cell_id'].values\n        candidate_cells.update(reported_cells)\n        print('Reported cellular lines for', example_comp_id,' :', reported_cells)\n        for cell in reported_cells:\n            similar_cells = list(cell_distance_list(int(cell)).index)\n            candidate_cells.update(similar_cells)\n            print('Similar cells to', cell,':', similar_cells)\n            \n        dist_list = distance_list(example_comp_id)\n        if len(dist_list) > 1:\n            print('Compound id', example_comp_id, 'has', len(dist_list)-1, 'similar compounds:',\n                  [dist_item[0] for dist_item in dist_list[1:]])\n            for comp in dist_list[1:]:\n                s = recomm.loc[recomm['comp_id'] == comp[0]]\n                if s.empty:\n                    print(comp[0], 'not in Collaborative-Filtering Recommendations')\n                    reported_cells = get_cells_for_comp(comp[0])['cell_id'].values\n                    candidate_cells.update(reported_cells)\n                    print('Reported cellular lines for', comp[0],' :', reported_cells)\n                    for cell in reported_cells:\n                        similar_cells = list(cell_distance_list(int(cell)).index)\n                        candidate_cells.update(similar_cells)\n                        print('Similar cells to', cell,':', similar_cells)\n                else:\n                    print('Collaborative-Filtering Recommendations for: ', comp[0])\n                    print(s['cell_id'].values)\n        else:\n            print('Compound id', example_comp_id, 'has no similar compounds')\n        return candidate_cells\n    else:\n        print('Collaborative-Filtering Recommendations for: ', example_comp_id)\n        print(s['cell_id'].values)\n        return s['cell_id'].values\n    \n            \n            \n\nexample_comp_id = 1\nprint('Candidate cells for', example_comp_id, ':',cold_start_recomm(example_comp_id))\nprint('='*80)\n","execution_count":25,"outputs":[{"output_type":"stream","text":"1 not in Collaborative-Filtering Recommendations\nReported cellular lines for 1  : ['646']\nSimilar cells to 646 : []\nCompound id 1 has 2 similar compounds: [1022, 550]\n1022 not in Collaborative-Filtering Recommendations\nReported cellular lines for 1022  : ['646' '687' '721']\nSimilar cells to 646 : []\nSimilar cells to 687 : []\nSimilar cells to 721 : [773]\n550 not in Collaborative-Filtering Recommendations\nReported cellular lines for 550  : ['436' '726' '791']\nSimilar cells to 436 : []\nSimilar cells to 726 : [20, 671]\nSimilar cells to 791 : [521]\nCandidate cells for 1 : {'721', 773, 521, '687', '646', '436', 20, '726', '791', 671}\n================================================================================\n","name":"stdout"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}