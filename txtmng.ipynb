{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Mining II Practical Assignment\n",
    "\n",
    "## Iván Marcelo Carrera Izurieta\n",
    "### Programa de Doutoramento em Ciência de Computadores FCUP.\n",
    "\n",
    "#### Predicting Cellular line - Drug Interactions as Recommender System\n",
    "This work presents an analysis for the relationships among cellular lines and pharmaceutical drugs.\n",
    "\n",
    "##### Web mining\n",
    "There are two main source databases for cellular lines: [Cellosaurus](https://web.expasy.org/cellosaurus/)\n",
    "and [ChEMBL](https://www.ebi.ac.uk/chembl/).\n",
    "First of all, we have to identify the cellular lines. File contains a list of cellular lines, with their synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CVCL_1567': ['NCI-H522', 'H522', 'NCIH522', 'H-522', 'NCI.H522', 'NCI522', 'CHEMBL3308392', 'NCI-522']}\n",
      "{'CVCL_1180': ['DOK', 'Dysplastic Oral Keratinocyte', 'CHEMBL3308727']}\n",
      "{'CVCL_0382': ['L1210', 'Leukemic 1210', 'L 1210', 'Leukemia L1210', 'Leukemia 1210', 'CHEMBL3308391', 'L-1210']}\n",
      "{'CVCL_0554': ['T24', 'T-24', 'CHEMBL3307700', 'T 24']}\n",
      "{'CVCL_1786': ['VMCub1', 'VM-CUB-I', 'VM-CUB-1', 'VM Cub 1', 'CHEMBL3308476', 'VMCUB1', 'VM-CUB1', 'VMCUB-1']}\n",
      "{'CVCL_1256': ['HCC1599', 'CHEMBL3308262', 'HCC-1599']}\n",
      "{'CVCL_1399': ['MC 116', 'MC-116', 'MC116', 'CHEMBL3308210']}\n",
      "{'CVCL_1084': ['BFTC909', 'BFTC 909', 'BFTC-909', 'CHEMBL3308710']}\n",
      "{'CVCL_1527': ['NCIH2107', 'H2107', 'NCI-H2107', 'H-2107']}\n",
      "{'CVCL_0076': ['CHEMBL3307273', 'SNU16', 'SNU-16', 'NCI-SNU-16']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "filename = 'data/cell_list.json'\n",
    "cell_list = json.load(open(filename,'r'))\n",
    "# print first 10 elements\n",
    "for cell in cell_list[:10]:\n",
    "    print(cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In order to form a corpus, we first have to retrieve all the paper abstracts from [PubMed](https://www.ncbi.nlm.nih.gov/pubmed/).\n",
    "PubMed has an API for retrieving papers included in the `Biopython` library. API access needs a key.\n",
    "\n",
    "Also, once the abstracts are retrieved, we can store them in memory as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# a few methods for parsing information\n",
    "# replace special chars\n",
    "def replace_spchars(original_string):\n",
    "    # new_string = original_string.encode('ascii', errors='ignore')\n",
    "    for c in ['\\n', '>', '<', '&', '(', ')', '[', ']', '%', '=', ',', '.', '+', '\\\\', '/']:\n",
    "        new_string = original_string.replace(c, ' ')\n",
    "    return new_string\n",
    "\n",
    "# transform an abstract from text to a dictionary\n",
    "def to_dict(abstract_string, cell_name):\n",
    "    abstract_ = dict()\n",
    "    doc_list = abstract_string.split('\\n\\n')\n",
    "    title = doc_list[1]\n",
    "    try:\n",
    "        title = title.replace('\\n', ' ')\n",
    "    except:\n",
    "        pass\n",
    "    title = replace_spchars(title)\n",
    "    len_list = []\n",
    "    for item in doc_list:\n",
    "        len_list.append(len(item))\n",
    "        if 'PMID:' in item:\n",
    "            item = item.split('PMID:')[1]\n",
    "            try:\n",
    "                item = item.replace(' [Indexed for MEDLINE]', '')\n",
    "            except:\n",
    "                pass\n",
    "            item = item.replace(' ', '')\n",
    "            index = 'PMID:' + item\n",
    "    # abstract should be the biggest item of doc_list\n",
    "    abstract = doc_list[len_list.index(max(len_list))]\n",
    "    abstract = replace_spchars(abstract).replace('\\n', ' ')\n",
    "    if abstract.startswith('Author information:'):\n",
    "        abstract = ''\n",
    "    abstract = (title + ' ' + abstract)\n",
    "    abstract_['title'] = title\n",
    "    abstract_['index'] = index\n",
    "    abstract_['document'] = abstract\n",
    "    abstract_['cell_id'] = cell_name\n",
    "    return abstract_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`Biopython` includes the `Entrez` library for accessing PubMed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "import time\n",
    "import os\n",
    "# list_toquery transforms the list of synonyms into a query\n",
    "def list_toquery(list_):\n",
    "    string = ''\n",
    "    if list_ is None:\n",
    "        print('List is NONE')\n",
    "    if type(list_) is str:\n",
    "        list_ = [list_]\n",
    "    for element in list_:\n",
    "        if element is None:\n",
    "            x = ''\n",
    "        else:\n",
    "            x = str(element)\n",
    "        if x != '':\n",
    "            string = string + '(\"' + x + '\"[Title/Abstract]) OR '\n",
    "    return string[:-4] + ' AND ((cell line[Title/Abstract]) OR (cellular line[Title/Abstract]) OR ' \\\n",
    "                         '(cell-line[Title/Abstract]))'\n",
    "\n",
    "# query returns a list of PubMed IDs\n",
    "def search_idlist(query):\n",
    "    Entrez.email = 'ivan.carrera@epn.edu.ec'\n",
    "    Entrez.api_key = 'e0cd8267acda02738ba691d40bda130c4808'\n",
    "    try:\n",
    "        handle = Entrez.esearch(db='pubmed', sort='relevance', retmax='5000', retmode='xml', term=query)\n",
    "        results = Entrez.read(handle)\n",
    "    except Exception as e:\n",
    "        print('Something is happening with queries about: ', query, e)\n",
    "        time.sleep(2) # this sleep is performed when PubMed servers reject queries\n",
    "        return search_idlist(query)\n",
    "    return results['IdList']\n",
    "\n",
    "# once you have a PubMed ID, you can retrieve the abstract\n",
    "def get_abstract(pmid):\n",
    "    Entrez.api_key = 'e0cd8267acda02738ba691d40bda130c4808'\n",
    "    try:\n",
    "        handle = Entrez.efetch(db='pubmed', id=pmid, retmode='text', rettype='abstract')\n",
    "        return handle.read()\n",
    "    except Exception as e:\n",
    "        print(pmid, e)\n",
    "\n",
    "# abstracts have to be processed and stored\n",
    "def process_abstracts(cell_):\n",
    "    file_prefix = 'data/cell_json/cell_abstracts_'\n",
    "    cell_id = list(cell_.keys())[0]\n",
    "    if os.path.exists(file_prefix + replace_spchars(cell_id) + '.json'):\n",
    "        print(cell_id, 'already exists')\n",
    "        pass\n",
    "    else:\n",
    "        #global gene_list\n",
    "        cell_abstracts = dict()\n",
    "        keyword_list = list(cell_.values())[0]\n",
    "        query = list_toquery(keyword_list)\n",
    "        idlist = search_idlist(query)\n",
    "        # print(cell_id, len(idlist), 'abstracts')\n",
    "        cell_abstracts['cell_id'] = cell_id\n",
    "        cell_abstracts['documents'] = list()\n",
    "        try:\n",
    "            for id_item in idlist:\n",
    "                abstract_text = get_abstract(id_item)\n",
    "                abstract_dict = to_dict(abstract_text, cell_name=cell_id)\n",
    "                cell_abstracts['documents'].append(abstract_dict)\n",
    "        except Exception as e:\n",
    "            print('Parsing error', e)\n",
    "            pass\n",
    "\n",
    "        json.dump(cell_abstracts, fp=open(file_prefix + replace_spchars(cell_id) + '.json', 'w'))\n",
    "        # print('got', len(cell_abstracts['documents']), 'abstracts to JSON file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Methods are defined. It is time for us to retrieve all abstracts.\n",
    "In parallel, because this can be very time consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVCL_1567 already exists\n",
      "CVCL_1180 already exists\n",
      "CVCL_0382 already exists\n",
      "CVCL_0554 already exists\n",
      "CVCL_1786 already exists\n",
      "CVCL_1256 already exists\n",
      "CVCL_1399 already exists\n",
      "CVCL_1084 already exists\n",
      "CVCL_1527 already exists\n",
      "CVCL_0076 already exists\n",
      "Abstract retrieving time: 0.011s\n"
     ]
    }
   ],
   "source": [
    "# this should be done in parallel\n",
    "# Binder does not support multiprocessing package\n",
    "from time import time\n",
    "t0 = time()\n",
    "# Only retrieving 10 first cell lines\n",
    "for cell_ in cell_list[:10]:\n",
    "    process_abstracts(cell_)\n",
    "retrieve_time = time() - t0\n",
    "print(\"Abstract retrieving time: %0.3fs\" % retrieve_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Text mining\n",
    "##### Text pre-processing\n",
    "We have a list of files. One file per cellular line. Each file contains a document for each abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684.5 files\n",
      "An example:\n",
      "{\"cell_id\": \"A2780 cisR\", \"documents\": [{\"title\": \"Changes in the in vitro activity of platinum drugs when administered in two aliquots.\", \"index\": \"PMID:27566066\", \"document\": \"Changes in the in vitro activity of platinum drugs when administered in two aliquots. BACKGROUND: The management of ovarian cancer remains a challenge. Because of the  lack of early symptoms, it is often diagnosed at a late stage when it is likely to have metastasized beyond ovaries. Currently, platinum based chemotherapy is the primary treatment for the disease. However acquired drug resistance remains an on-going problem. As cisplatin brings about apoptosis by intrinsic and extrinsic pathways, this study aimed to determine changes in activity of platinum drugs when administered in two aliquots as against a bolus and sought to determine association with changes in GSH, speciation of platinum drugs and changes in protein expression. METHODS: The efficacy of administering cisplatin, carboplatin and oxaliplatin i\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#filedir = '/home/ivan/ccap/data/cell_json/'\n",
    "filedir = 'C:\\\\Users\\\\ivanc\\\\PycharmProjects\\\\ccap\\\\data\\\\cell_json\\\\'\n",
    "filelist = os.listdir(filedir)\n",
    "print(len(filelist)/2, 'files')\n",
    "print('An example:')\n",
    "with open(filedir + filelist[0],'r') as f:\n",
    "    print(f.readline()[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Once we have the files, we can create a corpus.\n",
    "We retrieve all abstracts from the JSON files to form the corpus.\n",
    "For relevance, we inly select cellular lines with more than 10 abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5752 documents in corpus, from 240 cell lines\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "corpus = list()\n",
    "cell_class_list = list()\n",
    "for file in filelist:\n",
    "    if file.startswith('cell_abstracts_'):\n",
    "        cell = json.load(fp=open(filedir + file,'r'))\n",
    "        cell_id = cell['cell_id']\n",
    "        n_documents = len(cell['documents'])\n",
    "        # print(file, n_documents)\n",
    "        # Use only if cell line has at least 10 abstracts\n",
    "        if int(n_documents) > 10:\n",
    "            for document in cell['documents']:\n",
    "                abstract = document['document']\n",
    "                index = document['index']\n",
    "                corpus.append(abstract)\n",
    "                cell_class_list.append(cell_id)\n",
    "cell_set = set(cell_class_list)\n",
    "print(len(corpus), 'documents in corpus, from', len(cell_set), 'cell lines')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Corpus is now populated.\n",
    "Now, we want to process the abstracts with TF-IDF.\n",
    "We transform the corpus into a Document-Term Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTM shape: (5752, 14314)\n",
      "Top 20 words\n",
      "[('cell', 1.012946296985861), ('line', 1.0271334475144003), ('wa', 1.2550212229174793), ('studi', 1.5130878713156721), ('result', 1.5268287687027096), ('human', 1.5515655388767853), ('use', 1.5822051905658356), ('express', 1.5856335872541352), ('thi', 1.623818308977143), ('activ', 1.6431409995638697), ('effect', 1.6577981573638434), ('cancer', 1.716536974535502), ('induc', 1.931705295275342), ('inhibit', 1.9468234133620919), ('increas', 1.9644509884454053), ('protein', 1.9708554019186737), ('tumor', 2.0338347903517215), ('treatment', 2.1200467002767844), ('investig', 2.1269967416177566), ('level', 2.1475936757083796)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "stem = PorterStemmer()\n",
    "stemmed_corpus = list()\n",
    "for doc in corpus:\n",
    "    doc = doc.replace('.','').replace(',','').replace(';','').replace(':','')\n",
    "    stemmed_corpus.append(' '.join([stem.stem(x) for x in doc.split()]))\n",
    "\n",
    "target_names = list(cell_set)\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=1.0, min_df=2, strip_accents='ascii', stop_words='english',\n",
    "                             token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b')\n",
    "dtm = vectorizer.fit_transform(stemmed_corpus)\n",
    "print('DTM shape:', dtm.shape)\n",
    "\n",
    "wordfreq = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n",
    "print('Top 20 words')\n",
    "print(sorted(wordfreq.items(), key=lambda x: x[1])[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Document Classification\n",
    "We want to see if cellular lines have specific discriminant vocabulary.\n",
    "We divide `dtm` in trains and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Divide in train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dtm, cell_class_list, test_size=0.3, random_state=42,\n",
    "                                                    shuffle=True)\n",
    "# feature_names is the vocabulary of terms\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We define a `benchmark` method to apply to several classification methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from time import time\n",
    "\n",
    "def benchmark(clf, name):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "    print(\"confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    # clf_descr = str(clf).split('(')[0]\n",
    "    return clf, name, score, train_time, test_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We define 6 classification methods, some with variants:\n",
    "* Ridge Classifier\n",
    "* Passive-Aggressive\n",
    "* K Nearest Neighbors\n",
    "* Random Forest\n",
    "* Support Vector Machine\n",
    "* Stochastic Gradient Descent Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "                max_iter=None, normalize=False, random_state=None, solver='sag',\n",
      "                tol=0.01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:558: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n",
      "  '\"sag\" solver requires many iterations to fit '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 27.300s\n",
      "test time:  0.116s\n",
      "accuracy:   0.688\n",
      "confusion matrix:\n",
      "[[ 7  0  0 ...  0  0  0]\n",
      " [ 0  6  0 ...  0  0  0]\n",
      " [ 0  0 13 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  4  0  0]\n",
      " [ 0  0  0 ...  0  8  0]\n",
      " [ 0  0  0 ...  0  0  8]]\n",
      "\n",
      "================================================================================\n",
      "Passive-Aggressive\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "                            early_stopping=False, fit_intercept=True,\n",
      "                            loss='hinge', max_iter=50, n_iter_no_change=5,\n",
      "                            n_jobs=-1, random_state=None, shuffle=True,\n",
      "                            tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "                            warm_start=False)\n",
      "train time: 2.142s\n",
      "test time:  0.163s\n",
      "accuracy:   0.661\n",
      "confusion matrix:\n",
      "[[ 7  0  0 ...  0  0  0]\n",
      " [ 0  5  0 ...  0  0  0]\n",
      " [ 0  0 13 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  4  0  0]\n",
      " [ 0  0  0 ...  0  8  0]\n",
      " [ 0  0  0 ...  0  0  7]]\n",
      "\n",
      "================================================================================\n",
      "kNN\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=-1, n_neighbors=10, p=2,\n",
      "                     weights='uniform')\n",
      "train time: 0.021s\n",
      "test time:  0.814s\n",
      "accuracy:   0.445\n",
      "confusion matrix:\n",
      "[[ 7  0  0 ...  0  0  0]\n",
      " [ 0  4  0 ...  0  0  0]\n",
      " [ 0  0 13 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  3  0  0]\n",
      " [ 0  0  0 ...  0  4  0]\n",
      " [ 0  0  0 ...  0  0  7]]\n",
      "\n",
      "================================================================================\n",
      "Random forest\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
      "                       warm_start=False)\n",
      "train time: 15.332s\n",
      "test time:  0.563s\n",
      "accuracy:   0.721\n",
      "confusion matrix:\n",
      "[[ 7  0  0 ...  0  0  0]\n",
      " [ 0  4  0 ...  0  0  0]\n",
      " [ 0  0 13 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  4  0  0]\n",
      " [ 0  0  0 ...  0  9  0]\n",
      " [ 0  0  0 ...  0  0  7]]\n",
      "\n",
      "================================================================================\n",
      "LinearSVC L1\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "          verbose=0)\n",
      "train time: 14.015s\n",
      "test time:  0.077s\n",
      "accuracy:   0.791\n",
      "confusion matrix:\n",
      "[[ 7  0  0 ...  0  0  0]\n",
      " [ 0  6  0 ...  0  0  0]\n",
      " [ 0  0 13 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  3  0  0]\n",
      " [ 0  0  0 ...  0  7  0]\n",
      " [ 0  0  0 ...  0  0  7]]\n",
      "\n",
      "================================================================================\n",
      "LinearSVC L2\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
      "          verbose=0)\n",
      "train time: 15.872s\n",
      "test time:  0.073s\n",
      "accuracy:   0.674\n",
      "confusion matrix:\n",
      "[[ 7  0  0 ...  0  0  0]\n",
      " [ 0  6  0 ...  0  0  0]\n",
      " [ 0  0 13 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  4  0  0]\n",
      " [ 0  0  0 ...  0  8  0]\n",
      " [ 0  0  0 ...  0  0  7]]\n",
      "\n",
      "================================================================================\n",
      "SGDC L1\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n",
      "              n_iter_no_change=5, n_jobs=-1, penalty='l1', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "train time: 2.867s\n",
      "test time:  0.130s\n",
      "accuracy:   0.747\n",
      "confusion matrix:\n",
      "[[ 7  0  0 ...  0  0  0]\n",
      " [ 0  4  0 ...  0  0  0]\n",
      " [ 0  0 13 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  3  0  0]\n",
      " [ 0  0  0 ...  0  7  0]\n",
      " [ 0  0  0 ...  0  0  8]]\n",
      "\n",
      "================================================================================\n",
      "SGDC L2\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n",
      "              n_iter_no_change=5, n_jobs=-1, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "train time: 2.023s\n",
      "test time:  0.219s\n",
      "accuracy:   0.672\n",
      "confusion matrix:\n",
      "[[ 7  0  0 ...  0  0  0]\n",
      " [ 0  6  0 ...  0  0  0]\n",
      " [ 0  0 13 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  4  0  0]\n",
      " [ 0  0  0 ...  0  8  0]\n",
      " [ 0  0  0 ...  0  0  7]]\n",
      "\n",
      "================================================================================\n",
      "SGDC Elastic\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n",
      "              n_iter_no_change=5, n_jobs=-1, penalty='elasticnet', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "train time: 4.229s\n",
      "test time:  0.179s\n",
      "accuracy:   0.706\n",
      "confusion matrix:\n",
      "[[ 7  0  0 ...  0  0  0]\n",
      " [ 0  5  0 ...  0  0  0]\n",
      " [ 0  0 14 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  3  0  0]\n",
      " [ 0  0  0 ...  0  8  0]\n",
      " [ 0  0  0 ...  0  0  7]]\n",
      "\n",
      "================================================================================\n",
      "LinearSVC with L1-based feature selection\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(memory=None,\n",
      "         steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None,\n",
      "                                                     dual=False,\n",
      "                                                     fit_intercept=True,\n",
      "                                                     intercept_scaling=1,\n",
      "                                                     loss='squared_hinge',\n",
      "                                                     max_iter=1000,\n",
      "                                                     multi_class='ovr',\n",
      "                                                     penalty='l1',\n",
      "                                                     random_state=None,\n",
      "                                                     tol=0.001, verbose=0),\n",
      "                                 max_features=None, norm_order=1, prefit=False,\n",
      "                                 threshold=None)),\n",
      "                ('classification',\n",
      "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
      "                           fit_intercept=True, intercept_scaling=1,\n",
      "                           loss='squared_hinge', max_iter=1000,\n",
      "                           multi_class='ovr', penalty='l2', random_state=None,\n",
      "                           tol=0.0001, verbose=0))],\n",
      "         verbose=False)\n",
      "train time: 17.553s\n",
      "test time:  0.058s\n",
      "accuracy:   0.731\n",
      "confusion matrix:\n",
      "[[ 7  0  0 ...  0  0  0]\n",
      " [ 0  6  0 ...  0  0  0]\n",
      " [ 0  0 14 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  4  0  0]\n",
      " [ 0  0  0 ...  0  8  0]\n",
      " [ 0  0  0 ...  0  0  7]]\n",
      "\n",
      "================================================================================\n",
      "Sorted methods by score:\n",
      "[(LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "          verbose=0), 'LinearSVC L1', 0.7914252607184241, 14.014665126800537, 0.07701754570007324), (SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n",
      "              n_iter_no_change=5, n_jobs=-1, penalty='l1', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False), 'SGDC L1', 0.7468134414831982, 2.8667197227478027, 0.13003325462341309), (Pipeline(memory=None,\n",
      "         steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None,\n",
      "                                                     dual=False,\n",
      "                                                     fit_intercept=True,\n",
      "                                                     intercept_scaling=1,\n",
      "                                                     loss='squared_hinge',\n",
      "                                                     max_iter=1000,\n",
      "                                                     multi_class='ovr',\n",
      "                                                     penalty='l1',\n",
      "                                                     random_state=None,\n",
      "                                                     tol=0.001, verbose=0),\n",
      "                                 max_features=None, norm_order=1, prefit=False,\n",
      "                                 threshold=None)),\n",
      "                ('classification',\n",
      "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
      "                           fit_intercept=True, intercept_scaling=1,\n",
      "                           loss='squared_hinge', max_iter=1000,\n",
      "                           multi_class='ovr', penalty='l2', random_state=None,\n",
      "                           tol=0.0001, verbose=0))],\n",
      "         verbose=False), 'LinearSVC with L1-based feature selection', 0.7305909617612978, 17.553405046463013, 0.057898759841918945), (RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
      "                       warm_start=False), 'Random forest', 0.7213209733487833, 15.331809997558594, 0.5631504058837891), (SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n",
      "              n_iter_no_change=5, n_jobs=-1, penalty='elasticnet', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False), 'SGDC Elastic', 0.7062572421784473, 4.229059457778931, 0.1790480613708496), (RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "                max_iter=None, normalize=False, random_state=None, solver='sag',\n",
      "                tol=0.01), 'Ridge Classifier', 0.6877172653534183, 27.29985237121582, 0.11602973937988281), (LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
      "          verbose=0), 'LinearSVC L2', 0.6743916570104287, 15.871990203857422, 0.07301640510559082), (SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n",
      "              n_iter_no_change=5, n_jobs=-1, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False), 'SGDC L2', 0.6720741599073001, 2.022512674331665, 0.2190563678741455), (PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "                            early_stopping=False, fit_intercept=True,\n",
      "                            loss='hinge', max_iter=50, n_iter_no_change=5,\n",
      "                            n_jobs=-1, random_state=None, shuffle=True,\n",
      "                            tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "                            warm_start=False), 'Passive-Aggressive', 0.6610660486674391, 2.1422955989837646, 0.16304373741149902), (KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=-1, n_neighbors=10, p=2,\n",
      "                     weights='uniform'), 'kNN', 0.44495944380069524, 0.02100539207458496, 0.8143298625946045)]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for clf, name in [\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"sag\"), \"Ridge Classifier\"),\n",
    "        (PassiveAggressiveClassifier(max_iter=50, n_jobs=-1), \"Passive-Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=10, n_jobs=-1), \"kNN\"),\n",
    "        (RandomForestClassifier(n_jobs=-1), \"Random forest\"),\n",
    "        (LinearSVC(penalty=\"l1\", dual=False, tol=1e-3), \"LinearSVC L1\"),\n",
    "        (LinearSVC(penalty=\"l2\", dual=False, tol=1e-3), \"LinearSVC L2\"),\n",
    "        (SGDClassifier(alpha=.0001, max_iter=50, penalty=\"l1\", n_jobs=-1), \"SGDC L1\"),\n",
    "        (SGDClassifier(alpha=.0001, max_iter=50, penalty=\"l2\", n_jobs=-1), \"SGDC L2\"),\n",
    "        (SGDClassifier(alpha=.0001, max_iter=50, penalty=\"elasticnet\", n_jobs=-1),\"SGDC Elastic\"),\n",
    "        (Pipeline([('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False, tol=1e-3))),\n",
    "        ('classification', LinearSVC(penalty=\"l2\"))]), \"LinearSVC with L1-based feature selection\")\n",
    "]:\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf, name))\n",
    "print('=' * 80)\n",
    "print('Sorted methods by score:')\n",
    "print(sorted(results, key=lambda x: x[2], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We plot our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results_ = [[x[i] for x in results] for i in range(5)]\n",
    "\n",
    "clf, clf_names, score, training_time, test_time = results_\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
    "         color='c')\n",
    "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-.3, i, c)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('benchmarking_results.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to results, best classifier is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "          verbose=0)\n"
     ]
    }
   ],
   "source": [
    "bc = sorted(results, key=lambda x: x[2], reverse=True)[0][0]\n",
    "print(bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Feature Selection can show how many features are representative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTM shape: (5752, 14314)\n",
      "================================================================================\n",
      "k: 5000 DTM shape: (5752, 5000)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "          verbose=0)\n",
      "train time: 3.141s\n",
      "test time:  0.243s\n",
      "accuracy:   0.795\n",
      "confusion matrix:\n",
      "[[ 7  0  0 ...  0  0  0]\n",
      " [ 0  6  0 ...  0  0  0]\n",
      " [ 0  0 13 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  3  0  0]\n",
      " [ 0  0  0 ...  0  7  0]\n",
      " [ 0  0  0 ...  0  0  7]]\n",
      "\n",
      "================================================================================\n",
      "k: 8000 DTM shape: (5752, 8000)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "          verbose=0)\n",
      "train time: 6.333s\n",
      "test time:  0.373s\n",
      "accuracy:   0.793\n",
      "confusion matrix:\n",
      "[[ 7  0  0 ...  0  0  0]\n",
      " [ 0  6  0 ...  0  0  0]\n",
      " [ 0  0 13 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  3  0  0]\n",
      " [ 0  0  0 ...  0  7  0]\n",
      " [ 0  0  0 ...  0  0  7]]\n",
      "\n",
      "================================================================================\n",
      "k: 10000 DTM shape: (5752, 10000)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "          verbose=0)\n",
      "train time: 10.174s\n",
      "test time:  0.556s\n",
      "accuracy:   0.794\n",
      "confusion matrix:\n",
      "[[ 7  0  0 ...  0  0  0]\n",
      " [ 0  6  0 ...  0  0  0]\n",
      " [ 0  0 13 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  3  0  0]\n",
      " [ 0  0  0 ...  0  7  0]\n",
      " [ 0  0  0 ...  0  0  7]]\n",
      "\n",
      "================================================================================\n",
      "k: 12000 DTM shape: (5752, 12000)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "          verbose=0)\n",
      "train time: 12.136s\n",
      "test time:  0.556s\n",
      "accuracy:   0.794\n",
      "confusion matrix:\n",
      "[[ 7  0  0 ...  0  0  0]\n",
      " [ 0  6  0 ...  0  0  0]\n",
      " [ 0  0 13 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  3  0  0]\n",
      " [ 0  0  0 ...  0  7  0]\n",
      " [ 0  0  0 ...  0  0  7]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dtm_df = pd.DataFrame(dtm.todense())\n",
    "print('DTM shape:', dtm_df.shape)\n",
    "\n",
    "results = []\n",
    "for k in [5000, 8000, 10000, 12000]:\n",
    "    print('=' * 80)\n",
    "    dtm_fs = SelectKBest(chi2, k=k).fit_transform(dtm_df, cell_class_list)\n",
    "    print('k:', k, 'DTM shape:', dtm_fs.shape)\n",
    "    # Divide in train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dtm_fs, cell_class_list, test_size=0.3, random_state=42,\n",
    "                                                    shuffle=True)\n",
    "    clf = LinearSVC(penalty=\"l1\", dual=False, tol=1e-3)\n",
    "    results.append(benchmark(clf, 'LinearSVC'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}